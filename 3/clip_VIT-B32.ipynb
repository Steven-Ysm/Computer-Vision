{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pkg_resources import packaging\n",
    "import clip\n",
    "import os \n",
    "import skimage\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数: 151,277,313\n",
      "输入图片尺寸: 224\n",
      "文本长度: 77\n",
      "词表大小: 49408\n"
     ]
    }
   ],
   "source": [
    "#加载模型和图片处理器\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "model.cuda().eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"模型参数:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"输入图片尺寸:\", input_resolution)\n",
    "print(\"文本长度:\", context_length)\n",
    "print(\"词表大小:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_classifier_m(image_dir, subfolder, choice_label, top_k=5):\n",
    "    # image_dir不为文件夹\n",
    "    if not os.path.isdir(image_dir):\n",
    "        raise Exception(image_dir + ' 应该为一个图片文件夹')\n",
    "\n",
    "    # top_k小于choice_label数\n",
    "    if top_k > len(choice_label):\n",
    "        raise Exception('top_k大于候选标签数')\n",
    "\n",
    "    # 读取图片\n",
    "    original_images = []\n",
    "    images = []\n",
    "\n",
    "    for filename in [filename for filename in os.listdir(image_dir) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]:\n",
    "        image = Image.open(os.path.join(image_dir, filename)).convert(\"RGB\")\n",
    "\n",
    "        original_images.append(image)\n",
    "        images.append(preprocess(image))\n",
    "\n",
    "    # 输入特征\n",
    "    text_descriptions = [f\"This is a photo of a {label}\" for label in choice_label]\n",
    "    text_tokens = clip.tokenize(text_descriptions).cuda()\n",
    "\n",
    "    image_input = torch.tensor(np.stack(images)).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input).float()\n",
    "        text_features = model.encode_text(text_tokens).float()\n",
    "\n",
    "        image_features /= image_features.norm(dim = -1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim = -1, keepdim=True)\n",
    "\n",
    "    # 相似度得分\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    top_probs, top_labels = text_probs.cpu().topk(top_k, dim = -1)\n",
    "    show_result_m(subfolder, original_images, top_probs, top_labels, choice_label)\n",
    "    print(\"done!\")\n",
    "\n",
    "\n",
    "def show_result_m(subfolder, images, probs, labels, label_name):\n",
    "    os.makedirs(f'experiment/{subfolder}', exist_ok=True)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].axis(\"off\")\n",
    "\n",
    "        y = np.arange(probs.shape[-1])\n",
    "        ax[1].grid()\n",
    "        ax[1].barh(y, probs[i])\n",
    "        ax[1].invert_yaxis()\n",
    "        ax[1].set_axisbelow(True)\n",
    "        ax[1].set_yticks(y)\n",
    "        ax[1].set_yticklabels([label_name[index] for index in labels[i].numpy()])\n",
    "        ax[1].set_xlabel(\"probability\")\n",
    "\n",
    "        plt.subplots_adjust(wspace=1)\n",
    "        plt.savefig(f'experiment/{subfolder}/result_{i}.png', bbox_inches='tight')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "clip_classifier_m('miniimagenet', 'miniimagenet', ['house_finch', 'robin', 'triceratops', 'green_mamba', 'harvestman', 'toucan', 'goose', 'jellyfish', 'nematode', 'king_crab', 'dugong', 'Walker_hound', 'Ibizan_hound', 'Saluki', 'golden_retriever', 'Gordon_setter', 'komondor', 'boxer', 'Tibetan_mastiff', 'French_bulldog', 'malamute', 'dalmatian', 'Newfoundland', 'miniature_poodle', 'white_wolf', 'African_hunting_dog', 'Arctic_fox', 'lion', 'meerkat', 'ladybug', 'rhinoceros_beetle', 'ant', 'black-footed_ferret', 'three-toed_sloth', 'rock_beauty', 'aircraft_carrier', 'ashcan', 'barrel', 'beer_bottle', 'bookshop', 'cannon', 'carousel', 'carton', 'catamaran', 'chime', 'clog', 'cocktail_shaker', 'combination_lock', 'crate', 'cuirass', 'dishrag', 'dome', 'electric_guitar', 'file', 'fire_screen', 'frying_pan', 'garbage_truck', 'hair_slide', 'holster', 'horizontal_bar', 'hourglass', 'iPod', 'lipstick', 'miniskirt', 'missile', 'mixing_bowl', 'oboe', 'organ', 'parallel_bars', 'pencil_box', 'photocopier', 'poncho', 'prayer_rug', 'reel', 'school_bus', 'scoreboard', 'slot', 'snorkel', 'solar_dish', 'spider_web', 'stage', 'tank', 'theater_curtain', 'tile_roof', 'tobacco_shop', 'unicycle', 'upright', 'vase', 'wok', 'worm_fence', 'yawl', 'street_sign', 'consomme', 'trifle', 'hotdog', 'orange', 'cliff', 'coral_reef', 'bolete', 'ear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "clip_classifier_m('archive', 'archive', ['air hockey', 'ampute football', 'archery', 'arm wrestling', 'axe throwing', 'balance beam', 'barell racing', 'baseball', 'basketball', 'baton twirling', 'bike polo', 'billiards', 'bmx', 'bobsled', 'bowling', 'boxing', 'bull riding', 'bungee jumping', 'canoe slamon', 'cheerleading', 'chuckwagon racing', 'cricket', 'croquet', 'curling', 'disc golf', 'fencing', 'field hockey', 'figure skating men', 'figure skating pairs', 'figure skating women', 'fly fishing', 'football', 'formula 1 racing', 'frisbee', 'gaga', 'giant slalom', 'golf', 'hammer throw', 'hang gliding', 'harness racing', 'high jump', 'hockey', 'horse jumping', 'horse racing', 'horseshoe pitching', 'hurdles', 'hydroplane racing', 'ice climbing', 'ice yachting', 'jai alai', 'javelin', 'jousting', 'judo', 'lacrosse', 'log rolling', 'luge', 'motorcycle racing', 'mushing', 'nascar racing', 'olympic wrestling', 'parallel bar', 'pole climbing', 'pole dancing', 'pole vault', 'polo', 'pommel horse', 'rings', 'rock climbing', 'roller derby', 'rollerblade racing', 'rowing', 'rugby', 'sailboat racing', 'shot put', 'shuffleboard', 'sidecar racing', 'ski jumping', 'sky surfing', 'skydiving', 'snow boarding', 'snowmobile racing', 'speed skating', 'steer wrestling', 'sumo wrestling', 'surfing', 'swimming', 'table tennis', 'tennis', 'track bicycle', 'trapeze', 'tug of war', 'ultimate', 'uneven bars', 'volleyball', 'water cycling', 'water polo', 'weightlifting', 'wheelchair basketball', 'wheelchair racing', 'wingsuit flying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test(cifar):\n",
    "    correct = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(cifar)), desc=\"Processing\", ncols=100):\n",
    "        image, class_id = cifar[i]\n",
    "        image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "        text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar.classes]).to(device)\n",
    "\n",
    "        # Calculate features\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image_input)\n",
    "            text_features = model.encode_text(text_inputs)\n",
    "\n",
    "        # Pick the top 5 most similar labels for the image\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        values, indices = similarity[0].topk(5)\n",
    "\n",
    "        if indices[0] == class_id:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = 100 * correct / len(cifar)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR10: 10000\n",
      "CIFAR100: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████████████████████████████████████████| 10000/10000 [08:04<00:00, 20.65it/s]\n",
      "Processing: 100%|█████████████████████████████████████████████| 10000/10000 [23:45<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 Test Accuracy: 88.78%\n",
      "CIFAR100 Test Accuracy: 61.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR100, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dataset_path = os.path.join(os.getcwd(), \"dataset\")\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "cifar10 = CIFAR10(dataset_path, train=False, download=True)\n",
    "cifar100 = CIFAR100(dataset_path, train=False, download=True)\n",
    "\n",
    "print(f'CIFAR10: {len(cifar10)}')\n",
    "print(f'CIFAR100: {len(cifar100)}')\n",
    "\n",
    "cifar10_accuracy = test(cifar10)\n",
    "cifar100_accuracy = test(cifar100)\n",
    "\n",
    "print(f'CIFAR10 Test Accuracy: {cifar10_accuracy:.2f}%')\n",
    "print(f'CIFAR100 Test Accuracy: {cifar100_accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "719f98299ccca36a884f9d141671719e20aaacc8082e234f139e455a4a5b836e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
